/*
 * This file was automatically generated by EvoSuite
 * Sat Mar 09 23:07:34 GMT 2024
 */

package weka.core.tokenizers;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.util.NoSuchElementException;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.junit.runner.RunWith;
import weka.core.tokenizers.AlphabeticTokenizer;
import weka.core.tokenizers.Tokenizer;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true) 
public class AlphabeticTokenizer_ESTest extends AlphabeticTokenizer_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      alphabeticTokenizer0.m_CurrentPos = (-8);
      alphabeticTokenizer0.tokenize("tt}?Jq");
      alphabeticTokenizer0.m_CurrentPos = (-8);
      alphabeticTokenizer0.m_CurrentPos = 295;
      // Undeclared exception!
      try { 
        alphabeticTokenizer0.nextElement();
        fail("Expecting exception: NoSuchElementException");
      
      } catch(NoSuchElementException e) {
         //
         // No more tokens present
         //
         verifyException("weka.core.tokenizers.AlphabeticTokenizer", e);
      }
  }

  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      String[] stringArray0 = new String[4];
      stringArray0[0] = "3-fwB-ZJLdw";
      stringArray0[1] = "3-fwB-ZJLdw";
      stringArray0[2] = "3-fwB-ZJLdw";
      stringArray0[3] = "3-fwB-ZJLdw";
      Tokenizer.runTokenizer(alphabeticTokenizer0, stringArray0);
      assertEquals("Alphabetic string tokenizer, tokens are to be formed only from contiguous alphabetic sequences.", alphabeticTokenizer0.globalInfo());
  }

  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      String[] stringArray0 = new String[5];
      stringArray0[0] = "";
      stringArray0[1] = "@a ";
      stringArray0[2] = "-min <int>";
      stringArray0[3] = "";
      stringArray0[4] = "";
      Tokenizer.runTokenizer(alphabeticTokenizer0, stringArray0);
      assertEquals("Alphabetic string tokenizer, tokens are to be formed only from contiguous alphabetic sequences.", alphabeticTokenizer0.globalInfo());
  }

  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      alphabeticTokenizer0.m_CurrentPos = (-8);
      alphabeticTokenizer0.tokenize("tt}?Jq");
      alphabeticTokenizer0.m_CurrentPos = (-8);
      alphabeticTokenizer0.m_CurrentPos = 295;
      boolean boolean0 = alphabeticTokenizer0.hasMoreElements();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      alphabeticTokenizer0.tokenize("A}Y+![-=E<4Ampf");
      Object object0 = alphabeticTokenizer0.nextElement();
      assertEquals("A", object0);
  }

  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      alphabeticTokenizer0.tokenize("/{<]3l%");
      boolean boolean0 = alphabeticTokenizer0.hasMoreElements();
      assertTrue(boolean0);
  }

  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      String[] stringArray0 = new String[1];
      stringArray0[0] = "ur3AA;=ez'";
      Tokenizer.runTokenizer(alphabeticTokenizer0, stringArray0);
      boolean boolean0 = alphabeticTokenizer0.hasMoreElements();
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      // Undeclared exception!
      try { 
        alphabeticTokenizer0.tokenize((String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.tokenizers.AlphabeticTokenizer", e);
      }
  }

  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      // Undeclared exception!
      try { 
        alphabeticTokenizer0.nextElement();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.tokenizers.AlphabeticTokenizer", e);
      }
  }

  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      alphabeticTokenizer0.tokenize("");
      alphabeticTokenizer0.m_CurrentPos = (-2604);
      // Undeclared exception!
      try { 
        alphabeticTokenizer0.nextElement();
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index -2604 out of bounds for length 0
         //
         verifyException("weka.core.tokenizers.AlphabeticTokenizer", e);
      }
  }

  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      // Undeclared exception!
      try { 
        alphabeticTokenizer0.hasMoreElements();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("weka.core.tokenizers.AlphabeticTokenizer", e);
      }
  }

  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      alphabeticTokenizer0.tokenize("__Z|");
      alphabeticTokenizer0.m_CurrentPos = (-1);
      // Undeclared exception!
      try { 
        alphabeticTokenizer0.hasMoreElements();
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // Index -1 out of bounds for length 4
         //
         verifyException("weka.core.tokenizers.AlphabeticTokenizer", e);
      }
  }

  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      String[] stringArray0 = new String[7];
      stringArray0[0] = "8034";
      stringArray0[1] = "8034";
      stringArray0[2] = "8034";
      stringArray0[3] = "8034";
      stringArray0[4] = "8034";
      stringArray0[5] = "8034";
      stringArray0[6] = "VN9f1iH?NB|[(HAftb?";
      Tokenizer.tokenize((Tokenizer) alphabeticTokenizer0, stringArray0);
      // Undeclared exception!
      try { 
        alphabeticTokenizer0.nextElement();
        fail("Expecting exception: NoSuchElementException");
      
      } catch(NoSuchElementException e) {
         //
         // No more tokens present
         //
         verifyException("weka.core.tokenizers.AlphabeticTokenizer", e);
      }
  }

  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      String[] stringArray0 = new String[1];
      stringArray0[0] = "e.c2+zhxEW-OD";
      AlphabeticTokenizer.main(stringArray0);
      assertEquals(1, stringArray0.length);
  }

  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      String string0 = alphabeticTokenizer0.getRevision();
      assertEquals("8034", string0);
  }

  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      AlphabeticTokenizer alphabeticTokenizer0 = new AlphabeticTokenizer();
      String string0 = alphabeticTokenizer0.globalInfo();
      assertEquals("Alphabetic string tokenizer, tokens are to be formed only from contiguous alphabetic sequences.", string0);
  }
}
